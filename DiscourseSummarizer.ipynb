{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "075eb955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: evaluate in c:\\users\\rishabh\\anaconda3\\lib\\site-packages (0.4.2)\n",
      "Requirement already satisfied: datasets>=2.0.0 in c:\\users\\rishabh\\anaconda3\\lib\\site-packages (from evaluate) (2.20.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\rishabh\\anaconda3\\lib\\site-packages (from evaluate) (1.24.3)\n",
      "Requirement already satisfied: dill in c:\\users\\rishabh\\anaconda3\\lib\\site-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\rishabh\\anaconda3\\lib\\site-packages (from evaluate) (1.5.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\rishabh\\anaconda3\\lib\\site-packages (from evaluate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\rishabh\\anaconda3\\lib\\site-packages (from evaluate) (4.66.4)\n",
      "Requirement already satisfied: xxhash in c:\\users\\rishabh\\anaconda3\\lib\\site-packages (from evaluate) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\rishabh\\anaconda3\\lib\\site-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in c:\\users\\rishabh\\anaconda3\\lib\\site-packages (from evaluate) (2024.5.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in c:\\users\\rishabh\\anaconda3\\lib\\site-packages (from evaluate) (0.23.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\rishabh\\anaconda3\\lib\\site-packages (from evaluate) (23.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\rishabh\\anaconda3\\lib\\site-packages (from datasets>=2.0.0->evaluate) (3.9.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\rishabh\\anaconda3\\lib\\site-packages (from datasets>=2.0.0->evaluate) (16.1.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\users\\rishabh\\anaconda3\\lib\\site-packages (from datasets>=2.0.0->evaluate) (0.6)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\rishabh\\anaconda3\\lib\\site-packages (from datasets>=2.0.0->evaluate) (3.8.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\rishabh\\anaconda3\\lib\\site-packages (from datasets>=2.0.0->evaluate) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\rishabh\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.7.0->evaluate) (4.6.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rishabh\\anaconda3\\lib\\site-packages (from requests>=2.19.0->evaluate) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rishabh\\anaconda3\\lib\\site-packages (from requests>=2.19.0->evaluate) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rishabh\\anaconda3\\lib\\site-packages (from requests>=2.19.0->evaluate) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rishabh\\anaconda3\\lib\\site-packages (from requests>=2.19.0->evaluate) (2023.5.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\rishabh\\anaconda3\\lib\\site-packages (from tqdm>=4.62.1->evaluate) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\rishabh\\anaconda3\\lib\\site-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\rishabh\\anaconda3\\lib\\site-packages (from pandas->evaluate) (2022.7)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\rishabh\\anaconda3\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (22.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\rishabh\\anaconda3\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\rishabh\\anaconda3\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\rishabh\\anaconda3\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\rishabh\\anaconda3\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\rishabh\\anaconda3\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\rishabh\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe80aacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import pipeline  \n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "from datasets import Dataset, DatasetDict\n",
    "from evaluate import load\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b5eb960",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(r\"C:\\Users\\Rishabh\\Desktop\\Samsum\\samsum-train.csv\")\n",
    "test_df = pd.read_csv(r\"C:\\Users\\Rishabh\\Desktop\\Samsum\\samsum-test.csv\")\n",
    "val_df = pd.read_csv(r\"C:\\Users\\Rishabh\\Desktop\\Samsum\\samsum-validation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e535d790",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.dropna(axis = 0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe6591a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = 't5-small'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cee0f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanse(text):\n",
    "    clean = re.compile('<.*?>')\n",
    "    clean = re.sub(clean, '', text)\n",
    "\n",
    "    clean = '\\n'.join([line for line in clean.split('\\n') if not re.match('.*:\\s*$', line)])\n",
    "\n",
    "    return clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f4861d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['dialogue'] = train_df['dialogue'].apply(cleanse)\n",
    "val_df['dialogue'] = val_df['dialogue'].apply(cleanse)\n",
    "test_df['dialogue'] = test_df['dialogue'].apply(cleanse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "628db0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['summary'] = train_df['summary'].apply(cleanse)\n",
    "val_df['summary'] = val_df['summary'].apply(cleanse)\n",
    "test_df['summary'] = test_df['summary'].apply(cleanse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0b5a21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_pandas(train_df, preserve_index=False)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "val_dataset = Dataset.from_pandas(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "976481e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dict = {\n",
    "    'train' : train_dataset,\n",
    "    'test': test_dataset,\n",
    "    'validation': val_dataset\n",
    "}\n",
    "\n",
    "data = DatasetDict(dataset_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f266a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "Dean: How are tou Laura?\r\n",
      "Dean: *you\r\n",
      "Laura: fine thanks, what's up with you? :)\r\n",
      "Dean: just studying, studying\r\n",
      "Dean: and then some studying :D\r\n",
      "Laura: sounds exciting :P\r\n",
      "Dean: not too much\r\n",
      "Laura: :D\r\n",
      "Dean: which is why I wanted to ask if you's like to have dinner with me tonight?\r\n",
      "Laura: That's sweet thank you\r\n",
      "Dean: buuut? :D\r\n",
      "Laura: I promised my mum I would help her tonight\r\n",
      "Dean: oh\r\n",
      "Laura: tomorrow?\r\n",
      "Dean: great!\r\n",
      "Laura: :)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Dean is studying a lot so he wanted to invite Laura for dinner tonight. Laura promised she would help her mum tonight. Laura and Dean will have dinner tomorrow. \n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "Jimmy: How are you?\r\n",
      "Greg: I'm wearing a cast :D\r\n",
      "Jimmy: seriously? fuuck\r\n",
      "Jimmy: do they even let you in when you're that drunk?\r\n",
      "Greg: they do and they hydrate you so you're not hungover the next day :D\r\n",
      "Jimmy: you fucker\r\n",
      "Greg: :D:D:D\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Greg is now wearing a cast. \n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "Erin: Hey! Sorry, but I can't meet with you today, I've got a sore throat and headache.\n",
      "Erin: I had to get away from the lecture earlier, because I feel terrible. :(\n",
      "Summer: Oh no! Well, get well soon!! :)\n",
      "Summer: ps. Are we meeting next week, or are you heading home earlier?\n",
      "Erin: I am coming back Home on Thursday, so see you on Tueday! ;)\n",
      "Summer: Can't wait to see you on Tuesday - I'll try to plan something fun ;)\n",
      "Erin: :D Thanks for tutoring me - I feel like my English has improved. ;)\n",
      "Summer: Well, looking at the results of your last test - I would definitely say so :)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Summer is teaching Erin English. Erin has to cancel on Summer today because she is sick. They will meet on Tuesday before Erin travels home on Thursday.\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "Linda: Ant do you have the copy of the recent program for the conference in two weeks?\n",
      "Linda: Jason is asking if we can amend a set of dates to the schedule\n",
      "Linda: Some sections are not correct\n",
      "Anthea: I'm just adding a few bits of text right now\n",
      "Anthea: I can update the other sections too if you like?\n",
      "Anthea: Just send me the details\n",
      "Anthea: I'll have it ready before lunch\n",
      "Linda: Oh ok, perfect!\n",
      "Linda: So, the second section should read as follows\n",
      "Linda: 22nd Mar - Balldin room (live chat with Edwin Harris)\n",
      "Linda: 22nd Mar - Hurman room - (live chat with Emilia Thornsmith)\n",
      "Linda: 23rd Mar - Balldin room - Presentation of new stocks \n",
      "Anthea: Ok!\n",
      "Anthea: I'll get back to you in a bit\n",
      "Linda: Thanks\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Anthea is updating the recent program for the conference in two weeks. Jason wanted to amend a set of dates and Linda forwarded them to Anthea.\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "Henry: I'm slowly loosing faith in humanity...\r\n",
      "Luke: not a start of a conversation I'd expect but go on :P\r\n",
      "Henry: Well it is a justified exaggeration.\r\n",
      "Luke: let me be the judge of that\r\n",
      "Henry: I just read some \"interesting\" articles about the new Rise of the Shield Hero anime\r\n",
      "Luke: oh great, they are at it again?\r\n",
      "Henry: Goblin Slayer part 2\r\n",
      "Luke: what's the problem this time?\r\n",
      "Henry: Depiction of women and slavery\r\n",
      "Luke: I can see the part with slavery but why depiction of woman?\r\n",
      "Henry: Well you know, how the girl falsely accused the main hero and made him look like a scumbag\r\n",
      "Luke: well she kinda did that, so what's the problem?\r\n",
      "Henry: Giving a bad image to women I guess\r\n",
      "Henry: I don't really understand\r\n",
      "Luke: you're not the only one\r\n",
      "Henry: Or maybe I don't want to understand\r\n",
      "Henry: Because if I do, my first statement will definitely be true\r\n",
      "Luke: they fail to see some major things\r\n",
      "Luke: it's fiction\r\n",
      "Luke: going on a crusade against an anime just damages the things they fighting for\r\n",
      "Luke: honestly it's borderline ridicule\r\n",
      "Henry: You don't need to tell me that\r\n",
      "Henry: And they just won't listen\r\n",
      "Luke: let them be\r\n",
      "Luke: I don't think their \"crusades\" will change anything\r\n",
      "Luke: and we'll just keep watching what we enjoy\r\n",
      "Henry: True\r\n",
      "Henry: Just needed to get that out of my chest\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Luke and Henry are unhappy about people being on a crusade against the anime, this time the Rise of the Shield Hero. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "    idx = random.randint(0, 2000)\n",
    "    sample = data[\"train\"][idx]\n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"=\"*100)\n",
    "    print(sample[\"dialogue\"])\n",
    "    print(\"-\"*100)\n",
    "    print(sample[\"summary\"])\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5892c888",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9976fde7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [8774, 100, 19, 1626, 19754, 5, 5, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('Hello This is Hakim..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ec1d9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'summarize:'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46260bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_dialogue_length = 1024\n",
    "max_summary_length = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e1b2eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_function(samples):\n",
    "    inputs = [prefix + doc for doc in samples[\"dialogue\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=max_dialogue_length, truncation=True)\n",
    "\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(samples[\"summary\"], max_length=max_summary_length, truncation=True, padding=\"max_length\")\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65574089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[21603, 10, 188, 1], [21603, 10, 51, 1], [21603, 10, 9, 1], [21603, 10, 29, 1], [21603, 10, 26, 1], [21603, 10, 9, 1], [21603, 10, 10, 1], [21603, 10, 1], [21603, 10, 196, 1], [21603, 10, 1], [21603, 10, 115, 1], [21603, 10, 9, 1], [21603, 10, 157, 1], [21603, 10, 15, 1], [21603, 10, 26, 1], [21603, 10, 1], [21603, 10, 1], [21603, 10, 75, 1], [21603, 10, 32, 1], [21603, 10, 32, 1], [21603, 10, 157, 1], [21603, 10, 23, 1], [21603, 10, 15, 1], [21603, 10, 7, 1], [21603, 10, 5, 1], [21603, 10, 1], [21603, 10, 308, 1], [21603, 10, 32, 1], [21603, 10, 1], [21603, 10, 63, 1], [21603, 10, 32, 1], [21603, 10, 76, 1], [21603, 10, 1], [21603, 10, 210, 1], [21603, 10, 9, 1], [21603, 10, 29, 1], [21603, 10, 17, 1], [21603, 10, 1], [21603, 10, 7, 1], [21603, 10, 32, 1], [21603, 10, 51, 1], [21603, 10, 15, 1], [21603, 10, 58, 1], [21603, 10, 1], [21603, 10, 1], [21603, 10, 683, 1], [21603, 10, 15, 1], [21603, 10, 52, 1], [21603, 10, 52, 1], [21603, 10, 63, 1], [21603, 10, 10, 1], [21603, 10, 1], [21603, 10, 134, 1], [21603, 10, 76, 1], [21603, 10, 52, 1], [21603, 10, 15, 1], [21603, 10, 55, 1], [21603, 10, 1], [21603, 10, 1], [21603, 10, 188, 1], [21603, 10, 51, 1], [21603, 10, 9, 1], [21603, 10, 29, 1], [21603, 10, 26, 1], [21603, 10, 9, 1], [21603, 10, 10, 1], [21603, 10, 1], [21603, 10, 196, 1], [21603, 10, 31, 1], [21603, 10, 40, 1], [21603, 10, 40, 1], [21603, 10, 1], [21603, 10, 115, 1], [21603, 10, 52, 1], [21603, 10, 23, 1], [21603, 10, 29, 1], [21603, 10, 122, 1], [21603, 10, 1], [21603, 10, 63, 1], [21603, 10, 32, 1], [21603, 10, 76, 1], [21603, 10, 1], [21603, 10, 17, 1], [21603, 10, 32, 1], [21603, 10, 51, 1], [21603, 10, 32, 1], [21603, 10, 52, 1], [21603, 10, 52, 1], [21603, 10, 32, 1], [21603, 10, 210, 1], [21603, 10, 1], [21603, 10, 10, 1], [21603, 10, 18, 1], [21603, 10, 61, 1]], 'attention_mask': [[1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1], [1, 1, 1, 1], [1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1], [1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1], [1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1], [1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]], 'labels': [21542, 13635, 5081, 11, 56, 830, 16637, 128, 5721, 5, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_function(data['train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e01806c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3f73c68a9a34828a51ddcf11f0a5c5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f688402221204821ba60736dcce24e83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/819 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "379b899345784215bf0463d07552573b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/818 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "final_data = data.map(preprocess_function, batched =True,\n",
    "                     remove_columns=['id', 'dialogue', 'summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b743b508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 512)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-5): 5 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-5): 5 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "76d1fff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "epochs = 4\n",
    "model_name = f\"{model_checkpoint}-transcript-summarizer\"\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    model_name,                                                        \n",
    "    evaluation_strategy=\"epoch\",                                       \n",
    "    learning_rate=2e-5,                            \n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=0.01, \n",
    "    save_total_limit=3,                      \n",
    "    # Save the model only 3 times\n",
    "    num_train_epochs=epochs,                                           \n",
    "    predict_with_generate=True,                                        \n",
    "    fp16=False,                                                         \n",
    "    push_to_hub=False                                                  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bef5c2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4e00511e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rouge_score in c:\\users\\rishabh\\anaconda3\\lib\\site-packages (0.1.2)\n",
      "Requirement already satisfied: absl-py in c:\\users\\rishabh\\anaconda3\\lib\\site-packages (from rouge_score) (2.1.0)\n",
      "Requirement already satisfied: nltk in c:\\users\\rishabh\\anaconda3\\lib\\site-packages (from rouge_score) (3.7)\n",
      "Requirement already satisfied: numpy in c:\\users\\rishabh\\anaconda3\\lib\\site-packages (from rouge_score) (1.24.3)\n",
      "Requirement already satisfied: six>=1.14.0 in c:\\users\\rishabh\\anaconda3\\lib\\site-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: click in c:\\users\\rishabh\\anaconda3\\lib\\site-packages (from nltk->rouge_score) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\rishabh\\anaconda3\\lib\\site-packages (from nltk->rouge_score) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\rishabh\\anaconda3\\lib\\site-packages (from nltk->rouge_score) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in c:\\users\\rishabh\\anaconda3\\lib\\site-packages (from nltk->rouge_score) (4.66.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\rishabh\\anaconda3\\lib\\site-packages (from click->nltk->rouge_score) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "063b2c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = load(\"rouge\")\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    \n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id) \n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
    "    \n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "    result = {key : value * 100 for key, value in result.items()}\n",
    "    \n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    \n",
    "    return {k: round(v,4) for k,v in result.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4eeda3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer  = Seq2SeqTrainer(model,\n",
    "                         args,\n",
    "                         train_dataset=final_data['train'],\n",
    "                         eval_dataset=final_data['validation'],\n",
    "                         tokenizer= tokenizer,\n",
    "                          compute_metrics= compute_metrics\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "05ffa1fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Rishabh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "48386b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rishabh\\anaconda3\\Lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 2000\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8000' max='8000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8000/8000 6:58:33, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Gen Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.546800</td>\n",
       "      <td>0.459514</td>\n",
       "      <td>36.837800</td>\n",
       "      <td>15.505700</td>\n",
       "      <td>31.015300</td>\n",
       "      <td>34.119800</td>\n",
       "      <td>14.909500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.496900</td>\n",
       "      <td>0.439746</td>\n",
       "      <td>38.029800</td>\n",
       "      <td>16.219900</td>\n",
       "      <td>32.191300</td>\n",
       "      <td>35.495500</td>\n",
       "      <td>15.910800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.491900</td>\n",
       "      <td>0.430752</td>\n",
       "      <td>38.141400</td>\n",
       "      <td>16.286700</td>\n",
       "      <td>32.389000</td>\n",
       "      <td>35.491000</td>\n",
       "      <td>15.324000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.471700</td>\n",
       "      <td>0.428678</td>\n",
       "      <td>38.153600</td>\n",
       "      <td>16.277700</td>\n",
       "      <td>32.296200</td>\n",
       "      <td>35.499500</td>\n",
       "      <td>15.561100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to t5-small-transcript-summarizer\\checkpoint-500\n",
      "Configuration saved in t5-small-transcript-summarizer\\checkpoint-500\\config.json\n",
      "Model weights saved in t5-small-transcript-summarizer\\checkpoint-500\\pytorch_model.bin\n",
      "tokenizer config file saved in t5-small-transcript-summarizer\\checkpoint-500\\tokenizer_config.json\n",
      "Special tokens file saved in t5-small-transcript-summarizer\\checkpoint-500\\special_tokens_map.json\n",
      "Copy vocab file to t5-small-transcript-summarizer\\checkpoint-500\\spiece.model\n",
      "Deleting older checkpoint [t5-small-transcript-summarizer\\checkpoint-1000] due to args.save_total_limit\n",
      "Saving model checkpoint to t5-small-transcript-summarizer\\checkpoint-1000\n",
      "Configuration saved in t5-small-transcript-summarizer\\checkpoint-1000\\config.json\n",
      "Model weights saved in t5-small-transcript-summarizer\\checkpoint-1000\\pytorch_model.bin\n",
      "tokenizer config file saved in t5-small-transcript-summarizer\\checkpoint-1000\\tokenizer_config.json\n",
      "Special tokens file saved in t5-small-transcript-summarizer\\checkpoint-1000\\special_tokens_map.json\n",
      "Copy vocab file to t5-small-transcript-summarizer\\checkpoint-1000\\spiece.model\n",
      "Deleting older checkpoint [t5-small-transcript-summarizer\\checkpoint-1500] due to args.save_total_limit\n",
      "Saving model checkpoint to t5-small-transcript-summarizer\\checkpoint-1500\n",
      "Configuration saved in t5-small-transcript-summarizer\\checkpoint-1500\\config.json\n",
      "Model weights saved in t5-small-transcript-summarizer\\checkpoint-1500\\pytorch_model.bin\n",
      "tokenizer config file saved in t5-small-transcript-summarizer\\checkpoint-1500\\tokenizer_config.json\n",
      "Special tokens file saved in t5-small-transcript-summarizer\\checkpoint-1500\\special_tokens_map.json\n",
      "Copy vocab file to t5-small-transcript-summarizer\\checkpoint-1500\\spiece.model\n",
      "Deleting older checkpoint [t5-small-transcript-summarizer\\checkpoint-2000] due to args.save_total_limit\n",
      "Saving model checkpoint to t5-small-transcript-summarizer\\checkpoint-2000\n",
      "Configuration saved in t5-small-transcript-summarizer\\checkpoint-2000\\config.json\n",
      "Model weights saved in t5-small-transcript-summarizer\\checkpoint-2000\\pytorch_model.bin\n",
      "tokenizer config file saved in t5-small-transcript-summarizer\\checkpoint-2000\\tokenizer_config.json\n",
      "Special tokens file saved in t5-small-transcript-summarizer\\checkpoint-2000\\special_tokens_map.json\n",
      "Copy vocab file to t5-small-transcript-summarizer\\checkpoint-2000\\spiece.model\n",
      "Deleting older checkpoint [t5-small-transcript-summarizer\\checkpoint-500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 818\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to t5-small-transcript-summarizer\\checkpoint-2500\n",
      "Configuration saved in t5-small-transcript-summarizer\\checkpoint-2500\\config.json\n",
      "Model weights saved in t5-small-transcript-summarizer\\checkpoint-2500\\pytorch_model.bin\n",
      "tokenizer config file saved in t5-small-transcript-summarizer\\checkpoint-2500\\tokenizer_config.json\n",
      "Special tokens file saved in t5-small-transcript-summarizer\\checkpoint-2500\\special_tokens_map.json\n",
      "Copy vocab file to t5-small-transcript-summarizer\\checkpoint-2500\\spiece.model\n",
      "Deleting older checkpoint [t5-small-transcript-summarizer\\checkpoint-1000] due to args.save_total_limit\n",
      "Saving model checkpoint to t5-small-transcript-summarizer\\checkpoint-3000\n",
      "Configuration saved in t5-small-transcript-summarizer\\checkpoint-3000\\config.json\n",
      "Model weights saved in t5-small-transcript-summarizer\\checkpoint-3000\\pytorch_model.bin\n",
      "tokenizer config file saved in t5-small-transcript-summarizer\\checkpoint-3000\\tokenizer_config.json\n",
      "Special tokens file saved in t5-small-transcript-summarizer\\checkpoint-3000\\special_tokens_map.json\n",
      "Copy vocab file to t5-small-transcript-summarizer\\checkpoint-3000\\spiece.model\n",
      "Deleting older checkpoint [t5-small-transcript-summarizer\\checkpoint-1500] due to args.save_total_limit\n",
      "Saving model checkpoint to t5-small-transcript-summarizer\\checkpoint-3500\n",
      "Configuration saved in t5-small-transcript-summarizer\\checkpoint-3500\\config.json\n",
      "Model weights saved in t5-small-transcript-summarizer\\checkpoint-3500\\pytorch_model.bin\n",
      "tokenizer config file saved in t5-small-transcript-summarizer\\checkpoint-3500\\tokenizer_config.json\n",
      "Special tokens file saved in t5-small-transcript-summarizer\\checkpoint-3500\\special_tokens_map.json\n",
      "Copy vocab file to t5-small-transcript-summarizer\\checkpoint-3500\\spiece.model\n",
      "Deleting older checkpoint [t5-small-transcript-summarizer\\checkpoint-2000] due to args.save_total_limit\n",
      "Saving model checkpoint to t5-small-transcript-summarizer\\checkpoint-4000\n",
      "Configuration saved in t5-small-transcript-summarizer\\checkpoint-4000\\config.json\n",
      "Model weights saved in t5-small-transcript-summarizer\\checkpoint-4000\\pytorch_model.bin\n",
      "tokenizer config file saved in t5-small-transcript-summarizer\\checkpoint-4000\\tokenizer_config.json\n",
      "Special tokens file saved in t5-small-transcript-summarizer\\checkpoint-4000\\special_tokens_map.json\n",
      "Copy vocab file to t5-small-transcript-summarizer\\checkpoint-4000\\spiece.model\n",
      "Deleting older checkpoint [t5-small-transcript-summarizer\\checkpoint-2500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 818\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to t5-small-transcript-summarizer\\checkpoint-4500\n",
      "Configuration saved in t5-small-transcript-summarizer\\checkpoint-4500\\config.json\n",
      "Model weights saved in t5-small-transcript-summarizer\\checkpoint-4500\\pytorch_model.bin\n",
      "tokenizer config file saved in t5-small-transcript-summarizer\\checkpoint-4500\\tokenizer_config.json\n",
      "Special tokens file saved in t5-small-transcript-summarizer\\checkpoint-4500\\special_tokens_map.json\n",
      "Copy vocab file to t5-small-transcript-summarizer\\checkpoint-4500\\spiece.model\n",
      "Deleting older checkpoint [t5-small-transcript-summarizer\\checkpoint-3000] due to args.save_total_limit\n",
      "Saving model checkpoint to t5-small-transcript-summarizer\\checkpoint-5000\n",
      "Configuration saved in t5-small-transcript-summarizer\\checkpoint-5000\\config.json\n",
      "Model weights saved in t5-small-transcript-summarizer\\checkpoint-5000\\pytorch_model.bin\n",
      "tokenizer config file saved in t5-small-transcript-summarizer\\checkpoint-5000\\tokenizer_config.json\n",
      "Special tokens file saved in t5-small-transcript-summarizer\\checkpoint-5000\\special_tokens_map.json\n",
      "Copy vocab file to t5-small-transcript-summarizer\\checkpoint-5000\\spiece.model\n",
      "Deleting older checkpoint [t5-small-transcript-summarizer\\checkpoint-3500] due to args.save_total_limit\n",
      "Saving model checkpoint to t5-small-transcript-summarizer\\checkpoint-5500\n",
      "Configuration saved in t5-small-transcript-summarizer\\checkpoint-5500\\config.json\n",
      "Model weights saved in t5-small-transcript-summarizer\\checkpoint-5500\\pytorch_model.bin\n",
      "tokenizer config file saved in t5-small-transcript-summarizer\\checkpoint-5500\\tokenizer_config.json\n",
      "Special tokens file saved in t5-small-transcript-summarizer\\checkpoint-5500\\special_tokens_map.json\n",
      "Copy vocab file to t5-small-transcript-summarizer\\checkpoint-5500\\spiece.model\n",
      "Deleting older checkpoint [t5-small-transcript-summarizer\\checkpoint-4000] due to args.save_total_limit\n",
      "Saving model checkpoint to t5-small-transcript-summarizer\\checkpoint-6000\n",
      "Configuration saved in t5-small-transcript-summarizer\\checkpoint-6000\\config.json\n",
      "Model weights saved in t5-small-transcript-summarizer\\checkpoint-6000\\pytorch_model.bin\n",
      "tokenizer config file saved in t5-small-transcript-summarizer\\checkpoint-6000\\tokenizer_config.json\n",
      "Special tokens file saved in t5-small-transcript-summarizer\\checkpoint-6000\\special_tokens_map.json\n",
      "Copy vocab file to t5-small-transcript-summarizer\\checkpoint-6000\\spiece.model\n",
      "Deleting older checkpoint [t5-small-transcript-summarizer\\checkpoint-4500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 818\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to t5-small-transcript-summarizer\\checkpoint-6500\n",
      "Configuration saved in t5-small-transcript-summarizer\\checkpoint-6500\\config.json\n",
      "Model weights saved in t5-small-transcript-summarizer\\checkpoint-6500\\pytorch_model.bin\n",
      "tokenizer config file saved in t5-small-transcript-summarizer\\checkpoint-6500\\tokenizer_config.json\n",
      "Special tokens file saved in t5-small-transcript-summarizer\\checkpoint-6500\\special_tokens_map.json\n",
      "Copy vocab file to t5-small-transcript-summarizer\\checkpoint-6500\\spiece.model\n",
      "Deleting older checkpoint [t5-small-transcript-summarizer\\checkpoint-5000] due to args.save_total_limit\n",
      "Saving model checkpoint to t5-small-transcript-summarizer\\checkpoint-7000\n",
      "Configuration saved in t5-small-transcript-summarizer\\checkpoint-7000\\config.json\n",
      "Model weights saved in t5-small-transcript-summarizer\\checkpoint-7000\\pytorch_model.bin\n",
      "tokenizer config file saved in t5-small-transcript-summarizer\\checkpoint-7000\\tokenizer_config.json\n",
      "Special tokens file saved in t5-small-transcript-summarizer\\checkpoint-7000\\special_tokens_map.json\n",
      "Copy vocab file to t5-small-transcript-summarizer\\checkpoint-7000\\spiece.model\n",
      "Deleting older checkpoint [t5-small-transcript-summarizer\\checkpoint-5500] due to args.save_total_limit\n",
      "Saving model checkpoint to t5-small-transcript-summarizer\\checkpoint-7500\n",
      "Configuration saved in t5-small-transcript-summarizer\\checkpoint-7500\\config.json\n",
      "Model weights saved in t5-small-transcript-summarizer\\checkpoint-7500\\pytorch_model.bin\n",
      "tokenizer config file saved in t5-small-transcript-summarizer\\checkpoint-7500\\tokenizer_config.json\n",
      "Special tokens file saved in t5-small-transcript-summarizer\\checkpoint-7500\\special_tokens_map.json\n",
      "Copy vocab file to t5-small-transcript-summarizer\\checkpoint-7500\\spiece.model\n",
      "Deleting older checkpoint [t5-small-transcript-summarizer\\checkpoint-6000] due to args.save_total_limit\n",
      "Saving model checkpoint to t5-small-transcript-summarizer\\checkpoint-8000\n",
      "Configuration saved in t5-small-transcript-summarizer\\checkpoint-8000\\config.json\n",
      "Model weights saved in t5-small-transcript-summarizer\\checkpoint-8000\\pytorch_model.bin\n",
      "tokenizer config file saved in t5-small-transcript-summarizer\\checkpoint-8000\\tokenizer_config.json\n",
      "Special tokens file saved in t5-small-transcript-summarizer\\checkpoint-8000\\special_tokens_map.json\n",
      "Copy vocab file to t5-small-transcript-summarizer\\checkpoint-8000\\spiece.model\n",
      "Deleting older checkpoint [t5-small-transcript-summarizer\\checkpoint-6500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 818\n",
      "  Batch size = 1\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=8000, training_loss=0.5627898540496826, metrics={'train_runtime': 25115.0168, 'train_samples_per_second': 0.319, 'train_steps_per_second': 0.319, 'total_flos': 321910474801152.0, 'train_loss': 0.5627898540496826, 'epoch': 4.0})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "52708f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 819\n",
      "  Batch size = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='819' max='819' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [819/819 24:28]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = trainer.evaluate(final_data['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a82499c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_loss                                    0.425\n",
      "eval_rouge1                                 38.491\n",
      "eval_rouge2                                 15.264\n",
      "eval_rougeL                                 31.897\n",
      "eval_rougeLsum                              35.336\n",
      "eval_gen_len                                15.858\n",
      "eval_runtime                              1474.313\n",
      "eval_samples_per_second                      0.556\n",
      "eval_steps_per_second                        0.556\n",
      "epoch                                          4.0\n"
     ]
    }
   ],
   "source": [
    "for k,v in results.items():\n",
    "    print(f\"{k:{30}}{round(v,3):{20}}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "384e6146",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer = pipeline('summarization', model = model, tokenizer = tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "72a15120",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 200, but you input_length is only 127. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=63)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Dialogue:\n",
      "Richie: Pogba\n",
      "Clay: Pogboom\n",
      "Richie: what a s strike yoh!\n",
      "Clay: was off the seat the moment he chopped the ball back to his right foot\n",
      "Richie: me too dude\n",
      "Clay: hope his form lasts\n",
      "Richie: This season he's more mature\n",
      "Clay: Yeah, Jose has his trust in him\n",
      "Richie: everyone does\n",
      "Clay: yeah, he really deserved to score after his first 60 minutes\n",
      "Richie: reward\n",
      "Clay: yeah man\n",
      "Richie: cool then \n",
      "Clay: cool\n",
      "----------------------------------------------------------------------------------------------------\n",
      "summary:\n",
      "Richie and Clay saw a very good football game, with one football player chopping the ball back to his foot, which was particularly exciting. Jose has trust in that player. \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Predicted:\n",
      "Pogboom Richie was off the seat when he chopped the ball back to his right foot. Jose has his trust in him.\n",
      "====================================================================================================\n",
      "Dialogue:\n",
      "Lincoln: Heeyyy ;* whats up\n",
      "Fatima: I talked to Jenson, he’s not too happy ;p\n",
      "Lincoln: the place sucks??\n",
      "Fatima: No, the place is ok, I think, we can go there, it’s about Alene\n",
      "Lincoln: typical, dont worry about it\n",
      "Fatima: He thinks she may have a depression :[\n",
      "Lincoln: nothin new, everyone has it, she needs a doctor then\n",
      "Fatima: But she won’t go ;/\n",
      "Lincoln: so she’s destroying her life fuck it its not your problem\n",
      "Fatima: It is, they’re both my friends!\n",
      "Lincoln: you better think what to do if they break up\n",
      "Fatima: Ehh yes Ill have a problem ;//\n",
      "Lincoln: both blaming each other and talking with you about it, perfect\n",
      "Fatima: Alene is just troubled… She’d been through a lot…\n",
      "Lincoln: everyone has their problems, the question is are ya doin sth about them\n",
      "Fatima: She has problems facing it, don’t be surprised :[\n",
      "Lincoln: then it is her problem\n",
      "Fatima: You are so cruel at times… o.O\n",
      "Lincoln: maybe, for me its just a common sense\n",
      "Fatima: Why can’t everyone be just happy???\n",
      "Lincoln: youll not understand, you had good childhood, nice parents, you have no idea\n",
      "Fatima: Probably, true… Well I can be just grateful o.o\n",
      "Lincoln: do that and stop worrying about others, youre way to bautful for that <3\n",
      "Fatima: :*:*:*\n",
      "----------------------------------------------------------------------------------------------------\n",
      "summary:\n",
      "Fatima is worried about Jenson and Alene. Alene has issues. Lincoln doesn't want Fatima to worry about others too much.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Predicted:\n",
      "Fatima and Alene are both friends. They blame each other and talk with them about it. They have a problem with Alene.\n",
      "====================================================================================================\n",
      "Dialogue:\n",
      "Ollie: Okay, Kelly! Ur up nxt!\n",
      "Kelly: Me? I don't wanna.\n",
      "Mickey: C'mon!\n",
      "Jessica: Yeah! What's yours?\n",
      "Kelly: Fine. It's a sculpture garden in Finnland.\n",
      "Ollie: What's scary about sculptures? Wait! Do they resemble vampires and stuff?\n",
      "Mickey: Nah, I'm sure they look rly nice.\n",
      "Kelly: It's not the sculptures, it's the amount of them and their faces!\n",
      "Jessica: Faces? What faces?\n",
      "Kelly: Well, they resemble ppl in different activities like hugging, training, doing sport and so on. But the faces are just morbid and there's like a hundred of them. All staring at you!\n",
      "Ollie: Another one?\n",
      "Mickey: Certainly!\n",
      "Jessica: Well, Ollie, ur turn!\n",
      "Ollie: Nagoro village in Japan!\n",
      "Mickey: Y?\n",
      "Ollie: Well, maybe it's not scary, but it similar to Kelly's place. It's just creepy as hell.\n",
      "Jessica: Bt y?\n",
      "Ollie: Imagine a village with ppl living in it. And in the same village u have these human-sized figures. And there's more of them than the ppl that actually live there!\n",
      "Kelly: Creepy AH!\n",
      "Mickey: WTF?! Y would ppl even do that?\n",
      "Jessica: Idk. Idc. Never. Going. There.\n",
      "Ollie: See! Mine was the worst!\n",
      "Jessica: Bt not the scariest!\n",
      "Ollie: Point taken.\n",
      "Mickey: Listen, guys, fun talking to u, bt gotta go. \n",
      "Kelly: Yeah, me too. Bye!\n",
      "Jessica: Bye!\n",
      "Ollie: Cu!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "summary:\n",
      "Kelly is scared of sculpture garden figures in Finnland, she finds figure's faces morbid. For Ollie it's Nagoro village in Japan, it's creepy. \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Predicted:\n",
      "Kelly and Mickey have a sculpture garden in Finnland. They resemble vampires and stuff in different activities like hugging, training, doing sport, etc.\n",
      "====================================================================================================\n",
      "Dialogue:\n",
      "Charles: What are you up to this weekend?\n",
      "Camilla: Not much. Just some work and errands on Saturday, show Saturday night. Day of nothingness on Sundy.\n",
      "Charles: Sounds good. We are going to visit the German markets this weekend. Birmingham and Manchester both. Sausage overload!\n",
      "Camilla: Ooh, that sounds really good!\n",
      "Charles: Allegedly there are Christmas things going on but I just go for the sausage and beer!\n",
      "Camilla: What a shocker.\n",
      "Charles: I know!\n",
      "Camilla: I'll have to try to get there this year. I've not been for ages.\n",
      "Charles: Oh, yeah, they are good. Try the mulled wine too. That's nice.\n",
      "Camilla: Never had it. Is it served hot?\n",
      "Charles: Yes, exactly. And lots of spices. Usually a red but sometimes they offer a mulled white.\n",
      "Camilla: I'm good with red.\n",
      "Charles: Inspired us to make our own at Christmas last year, but nobody else drank it.\n",
      "Camilla: Bummer!\n",
      "Charles: More for me! But oh the hangover.\n",
      "Camilla: LOL!\n",
      "Charles: Anyway, that's the plan. Hope you have fun.\n",
      "Camilla: You too! \n",
      "Charles: Thanks!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "summary:\n",
      "Camilla has some errands to do on Saturday. Charles is visiting the German markets this weekend. They are talking about Christmas food and drinks.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Predicted:\n",
      "Charles is going to visit the German markets this weekend, Birmingham and Manchester both. Charles will have to try the sausage and beer this year. Camilla has not been for ages.\n",
      "====================================================================================================\n",
      "Dialogue:\n",
      "Abby: Have you talked to Miro?\n",
      "Dylan: No, not really, I've never had an opportunity\n",
      "Brandon: me neither, but he seems a nice guy\n",
      "Brenda: you met him yesterday at the party?\n",
      "Abby: yes, he's so interesting\n",
      "Abby: told me the story of his father coming from Albania to the US in the early 1990s\n",
      "Dylan: really, I had no idea he is Albanian\n",
      "Abby: he is, he speaks only Albanian with his parents\n",
      "Dylan: fascinating, where does he come from in Albania?\n",
      "Abby: from the seacoast\n",
      "Abby: Duress I believe, he told me they are not from Tirana\n",
      "Dylan: what else did he tell you?\n",
      "Abby: That they left kind of illegally\n",
      "Abby: it was a big mess and extreme poverty everywhere\n",
      "Abby: then suddenly the border was open and they just left \n",
      "Abby: people were boarding available ships, whatever, just to get out of there\n",
      "Abby: he showed me some pictures, like \n",
      "Dylan: insane\n",
      "Abby: yes, and his father was among the people\n",
      "Dylan: scary but interesting\n",
      "Abby: very!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "summary:\n",
      "Miro speaks Albanian with his parents. His family left Albania illegally in 1990s.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Predicted:\n",
      "Abby met Miro yesterday at the party. Abby tells him about his father coming from Albania to the US in the early 1990s.\n"
     ]
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "    idx = random.randint(0, 818)\n",
    "    \n",
    "    dialogue = data['test'][idx]['dialogue']\n",
    "    summary = data['test'][idx]['summary']\n",
    "    \n",
    "    predicted = summarizer(dialogue)\n",
    "    \n",
    "    print(\"=\"*100)\n",
    "    print(f\"Dialogue:\\n{dialogue}\")\n",
    "    print(\"-\"*100)\n",
    "    print(f\"summary:\\n{summary}\")\n",
    "    print(\"-\"*100)\n",
    "    print(f\"Predicted:\\n{predicted[0]['summary_text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1397fe8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary(dialogue):\n",
    "    inputs = tokenizer.encode(\"summarize: \" + dialogue, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "    summary_ids = model.generate(inputs, max_length=128, min_length=30, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "23f1ec59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Summary: Alice hasn't seen her keys, but she's supposed to leave them in 10 minutes. Bob left them on the counter. Bob doesn't remember taking them out of his bag.\n"
     ]
    }
   ],
   "source": [
    "dialogue = '''\n",
    "Alice: Bob, have you seen my keys? I can’t find them anywhere.\n",
    "Bob: No, I haven’t. Did you check your bag?\n",
    "Alice: Yes, I did. They’re not there. I’m supposed to leave in ten minutes.\n",
    "Bob: Let’s retrace your steps. Where did you go after coming home?\n",
    "Alice: I came in, put my coat on the chair, and went to the kitchen to make some tea.\n",
    "Bob: Let’s start there. Maybe you left them on the counter.\n",
    "Alice: I don’t remember taking them out of my bag in the kitchen, but it’s worth a look.\n",
    "Bob: Here they are! They were next to the kettle. You must have put them down when you made your tea.\n",
    "Alice: Oh, thank goodness! Thank you, Bob. I don’t know what I’d do without you.\n",
    "Bob: Anytime, Alice. Now go, or you’ll be late!'''\n",
    "summary = generate_summary(dialogue)\n",
    "print(\"Generated Summary:\", summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d949ff70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
